{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962964bb-9316-4393-893f-7481aeff2400",
   "metadata": {},
   "source": [
    "# Tutorial #3: Dataloading with `tensorflow-datasets` and PyTorch dataloading\n",
    "\n",
    "We'll look at two ways to load datasets, `tensorflow-datasets` and pytorch dataloading. To illustrate, we'll use the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3459aa-ed90-4d0b-84a4-065de9dfa66e",
   "metadata": {},
   "source": [
    "### 3.1: Tensorflow datasets data loading\n",
    "\n",
    "We'll use `tensorflow-datasets`, which uses the function `tfds.load` to load datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7962b2a6-32e2-4ffb-b0b2-df56e1cd426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds  # TFDS to download MNIST.\n",
    "import tensorflow as tf  # TensorFlow / `tf.data` operations.\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(0)  # Set the random seed for reproducibility.\n",
    "\n",
    "train_ds: tf.data.Dataset = tfds.load('mnist', split='train', data_dir='datasets/tensorflow_datasets')\n",
    "test_ds: tf.data.Dataset = tfds.load('mnist', split='test', data_dir='datasets/tensorflow_datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc8672-c19e-4af1-b893-bab1009817f7",
   "metadata": {},
   "source": [
    "`tfds` can be understood as a high-level wrapper around the `tensorflow` API `tf.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb9612f-e227-4209-906e-0e068dc4c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "<_PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(train_ds, tf.data.Dataset)\n",
    "print(train_ds)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43495d-1644-4192-b64e-64faa9f2fb38",
   "metadata": {},
   "source": [
    "Tensorflow datasets allow you to iterate over the examples in the dataset, with each example given as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487596a6-13fc-4f9f-b7aa-54cdbe45b6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'label'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 15:13:58.529434: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for mnist_example in train_ds.take(1):\n",
    "    print(mnist_example.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9b68c-1442-4aff-8e20-48b063ad2db6",
   "metadata": {},
   "source": [
    "The MNIST images are handwritten digits, with labels from 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cf0f0a-3e03-4720-80fd-0191cbba78a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 15:13:58.599546: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mnist_example in train_ds.take(2):\n",
    "    image = mnist_example['image']\n",
    "    label = mnist_example['label']\n",
    "    print(label)\n",
    "    print(type(image))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a91a2-058e-4298-9bde-1b681edec1cd",
   "metadata": {},
   "source": [
    "We can see the size of our training and testing datasets using the `.cardinality()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee3c82e0-eff3-4518-8353-e1e669240f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.cardinality().numpy())\n",
    "print(test_ds.cardinality().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e856e-fbba-46ee-bb2f-7e786a8c90eb",
   "metadata": {},
   "source": [
    "Since the values of the pixels in each image range from 0 to 255, we'll normalize them to between 0 and 1 using the following lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620f8f93-7c66-4d5a-a4d8-392194962373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train set\n",
    "train_ds = train_ds.map(\n",
    "  lambda sample: {\n",
    "    'image': tf.cast(sample['image'], tf.float32) / 255,\n",
    "    'label': sample['label'],\n",
    "  }\n",
    ") \n",
    "# Normalize test set\n",
    "test_ds = test_ds.map(\n",
    "  lambda sample: {\n",
    "    'image': tf.cast(sample['image'], tf.float32) / 255,\n",
    "    'label': sample['label'],\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a0ed1-6a4f-4ca1-b32b-197b50ad0a38",
   "metadata": {},
   "source": [
    "#### Improving dataset latency with `.prefetch(1)`\n",
    "\n",
    "We can benchmark the speed of dataloading with `tfds` using `.benchmark()`. Apparently using `.prefetch(1)` improves the speed of data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b7854a-4b33-45b5-ae8a-cb08c29fdd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff4e1bb58dc442c833406eb24224f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples/sec (First included) 66805.20 ex/sec (total: 60032 ex, 0.90 sec)\n",
      "Examples/sec (First only) 482.68 ex/sec (total: 32 ex, 0.07 sec)\n",
      "Examples/sec (First excluded) 72087.95 ex/sec (total: 60000 ex, 0.83 sec)\n",
      "\n",
      "************ Summary ************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8d5340224f4d47b0e8b47c97837dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples/sec (First included) 176964.26 ex/sec (total: 60032 ex, 0.34 sec)\n",
      "Examples/sec (First only) 1193.17 ex/sec (total: 32 ex, 0.03 sec)\n",
      "Examples/sec (First excluded) 192053.52 ex/sec (total: 60000 ex, 0.31 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>0.339232</td>\n",
       "      <td>60032</td>\n",
       "      <td>176964.263082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.026819</td>\n",
       "      <td>32</td>\n",
       "      <td>1193.165385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>0.312413</td>\n",
       "      <td>60000</td>\n",
       "      <td>192053.518709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=             duration  num_examples            avg\n",
       "first+lasts  0.339232         60032  176964.263082\n",
       "first        0.026819            32    1193.165385\n",
       "lasts        0.312413         60000  192053.518709, raw_stats=                      duration\n",
       "start_time        17654.029694\n",
       "first_batch_time  17654.056514\n",
       "end_time          17654.368927\n",
       "num_iter           1875.000000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_benchmark_example_1 = train_ds.batch(32)\n",
    "\n",
    "tfds.benchmark(ds_benchmark_example_1, batch_size=32)\n",
    "tfds.benchmark(ds_benchmark_example_1, batch_size=32)  # Second epoch faster due to auto-caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d599e1ee-dffa-4081-b2c1-5b4f720bfc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db71f14796c64880bf0690863923ae39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples/sec (First included) 199795.85 ex/sec (total: 60032 ex, 0.30 sec)\n",
      "Examples/sec (First only) 2377.40 ex/sec (total: 32 ex, 0.01 sec)\n",
      "Examples/sec (First excluded) 209054.41 ex/sec (total: 60000 ex, 0.29 sec)\n",
      "\n",
      "************ Summary ************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d8f8f233b84ec08a3a285ab3ec6893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples/sec (First included) 188515.48 ex/sec (total: 60032 ex, 0.32 sec)\n",
      "Examples/sec (First only) 1212.91 ex/sec (total: 32 ex, 0.03 sec)\n",
      "Examples/sec (First excluded) 205435.07 ex/sec (total: 60000 ex, 0.29 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>0.318446</td>\n",
       "      <td>60032</td>\n",
       "      <td>188515.478291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.026383</td>\n",
       "      <td>32</td>\n",
       "      <td>1212.906063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>0.292063</td>\n",
       "      <td>60000</td>\n",
       "      <td>205435.070341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=             duration  num_examples            avg\n",
       "first+lasts  0.318446         60032  188515.478291\n",
       "first        0.026383            32    1212.906063\n",
       "lasts        0.292063         60000  205435.070341, raw_stats=                      duration\n",
       "start_time        17654.680400\n",
       "first_batch_time  17654.706783\n",
       "end_time          17654.998846\n",
       "num_iter           1875.000000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_benchmark_example_2 = train_ds.batch(32).prefetch(1)\n",
    "\n",
    "tfds.benchmark(ds_benchmark_example_2, batch_size=32)\n",
    "tfds.benchmark(ds_benchmark_example_2, batch_size=32)  # Second epoch faster due to auto-caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa9d9e-b143-47bb-90c2-dcf0930e7217",
   "metadata": {},
   "source": [
    "In this example, using `.prefetch(1)` doesn't seem to make much of a differrence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201ea8d-1d2d-4a32-adb8-ce9614c14c15",
   "metadata": {},
   "source": [
    "#### Data loading with `tfds` method 1: Prespecified number of training iterations \n",
    "\n",
    "We want to load our data either with a given batch size for a certain number of epochs or with a certain number of training iterations. We'll start by loading our data with a prespecified number of training iterations.\n",
    "\n",
    "We'll load the dataset with 1000 training iterations and a batch size of 32, for a total of 32000 training examples.\n",
    "\n",
    "We'll start by reloading the dataset indefinitely using the `.repeat()` function. We then shuffle the dataset using a buffer size of 1024. To explain the `.shuffle()` function, see [this](https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-dataset) StackOverflow post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3271baae-ad98-4541-becf-fac1e3239a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 1000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892fa9dd-a018-4bce-a1a3-55aeb342f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1 = train_ds.repeat().shuffle(buffer_size = 1024) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5b01d-42be-4c8b-9ded-40cf7c924095",
   "metadata": {},
   "source": [
    "We can now take data indefinitely from our dataset. But we'll want to fetch data with a batch size of 32. For this, we'll use the functions `.batch(batch_size)` and the `.take(train_steps)`. We'll also use the `.prefetch(1)` function which apparently improves the latency of the dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bea61c4-36c5-4351-ab57-1f36cbda4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1 = train_ds_1.batch(batch_size, drop_remainder=True)\n",
    "train_ds_1 = train_ds_1.take(train_steps)\n",
    "train_ds_1 = train_ds_1.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d3de0-6050-4be1-b8d5-49ab40d5c007",
   "metadata": {},
   "source": [
    "We can now iterate over our dataset by converting the dataset to a numpy iterator, using the `.as_numpy_iterator()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c54a3a-9909-42f5-8e49-d1fa17a627bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_ds_1.as_numpy_iterator()):\n",
    "    pass\n",
    "    \n",
    "print(step)\n",
    "print(batch['image'].shape)\n",
    "print(batch['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f79154-e7d5-4d7d-955f-1a60a640ed29",
   "metadata": {},
   "source": [
    "As you can see, we've performed 1000 iterations over the dataset and each dataset has a batch size of 32. As we wanted!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70298133-9bca-4033-96ac-0f7ecfdbfe4e",
   "metadata": {},
   "source": [
    "#### Data loading with `tfds` method 2: Prespecified number of epochs\n",
    "\n",
    "We'll now perform a pre-specified number of epochs over the dataset. Instead of repeating an indefinite number of times, then batching, we'll need to batch our dataset first, then repeat `num_epochs` times. We'll also want to shuffle first, as this ensures that the batches in each epoch are different.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de94a717-2a54-4cd9-be76-e58ae7364623",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c657d4e-7e37-44a0-80a2-e8163fbbbbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_2 = train_ds.shuffle(buffer_size = 1024).batch(batch_size, drop_remainder=True).repeat(num_epochs).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ff598e-8ccc-4888-96c3-3ea793997783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375\n",
      "(32, 28, 28, 1)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for step, batch in enumerate(train_ds_2.as_numpy_iterator()):\n",
    "    counter += 1\n",
    "print(counter)\n",
    "print(batch['image'].shape)\n",
    "print(batch['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f9585-cc53-4447-8f3f-4c5c1d1af392",
   "metadata": {},
   "source": [
    "We've now performed 5 epochs over the dataset, as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca3439-00dc-404a-aae5-7703a50d0cb2",
   "metadata": {},
   "source": [
    "### 3.2: PyTorch data loading\n",
    "\n",
    "Loading datasets using PyTorch's `Dataloader` function is easy. We'll first import MNIST using `torchvision`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b3abe04-44c6-4bbd-898c-d24807405af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c887af31-0b54-44b2-b3f4-ef119a65f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c89200-4505-4cbc-924c-ec21e67cd546",
   "metadata": {},
   "source": [
    "We then convert the data into a `DataLoader` object, with a given batch size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d6bb56d-504f-43d8-ae44-cd8ba26fd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f7550-6e70-4b7e-8c69-6c4541fc8963",
   "metadata": {},
   "source": [
    "We can then iterate over the `DataLoader` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf7049c9-5d63-4b85-b124-04c09fcc3894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for step, (train_features, train_labels) in enumerate(train_dataloader):\n",
    "    pass\n",
    "print(step)\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3851f-e518-45cf-bb2a-9faf81ea557c",
   "metadata": {},
   "source": [
    "It looks like, if we want to convert these to numpy arrays, we'll have to manually convert them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
